# Toxic Comment Classification Challenge

## Overview
This project is part of my ongoing efforts to explore and understand the applications of machine learning and natural language processing in moderating online discussions. The goal is to build a model that can accurately classify toxic comments, which is a crucial step towards creating a safer and more respectful online environment.

The importance of this topic lies in promoting healthy online discussions, preventing cyberbullying, protecting online communities, and improving machine learning and natural language processing models and techniques.

## Dataset
The dataset used in this project is sourced from Kaggle's Toxic Comment Classification Challenge 2018. It includes a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. You can access the dataset [here](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge).

## Methodology
We explored various machine learning and natural language processing techniques to classify the comments. Our best model achieved a notable AUC-ROC score when generalized to unseen data, suggesting high accuracy in toxic comment classification.

## Report
The final report detailing our approach, methodology, and results is available in this repository.

## References
[1]Fortuna, P., & Nunes, S. (2018). A survey on automatic detection of hate speech in text. ACM Computing Surveys (CSUR), 51(4), 1-30.

[2]Kaggle. (2018). Toxic Comment Classification Challenge. Retrieved from https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge

[3]Dixon, L., Li, J., Sorensen, J., Thain, N., & Vasserman, L. (2018). Measuring and mitigating unintended bias in text classification. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society (pp. 67-73).

## License
The Toxic Comment Classification Challenge report contained herein are licensed under the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License. The software code is licensed under the MIT License. If re-using/re-mixing, please provide attribution and link to this webpage. See the license file for more information.
